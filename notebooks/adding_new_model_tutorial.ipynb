{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ProteinWorkshop` Tutorial, Part 4 - Adding a New Model\n",
    "![Models](../docs/source/_static/box_models.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ProteinWorkshop` encompasses several models as well as pre-trained weights for them so that you can readily use them. However, you may want to add your own model to the `ProteinWorkshop` to fulfill a specific use case. This tutorial will show you how to do that.\n",
    "\n",
    "To add your custom model to the `ProteinWorkshop`, you just have to follow the following 4-step procedure (created files in brackets):\n",
    "\n",
    "1. Create a new subclass of the `nn.Module` class (`my_new_model.py`).\n",
    "2. Create a new model config file to accompany the custom `MyNewModel` (`my_new_model.yaml`).\n",
    "3. Compose and instantiate your config for pre-training or finetuning using your model\n",
    "4. Use your custom model in a pre-training or finetuning task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new subclass of the `nn.Module` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference the `EGNNModel` below (i.e., `proteinworkshop/models/graph_encoders/egnn.py`) to fill out a custom `proteinworkshop/models/graph_encoders/my_new_model.py` in a similar style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class EGNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int = 5,\n",
    "        emb_dim: int = 128,\n",
    "        activation: str = \"relu\",\n",
    "        norm: str = \"layer\",\n",
    "        aggr: str = \"sum\",\n",
    "        pool: str = \"sum\",\n",
    "        residual: bool = True\n",
    "    ):\n",
    "        '''E(n) Equivariant GNN model\n",
    "\n",
    "        Args:\n",
    "            num_layers: (int) - number of message passing layers\n",
    "            emb_dim: (int) - hidden dimension\n",
    "            in_dim: (int) - initial node feature dimension\n",
    "            out_dim: (int) - output number of classes\n",
    "            activation: (str) - non-linearity within MLPs (swish/relu)\n",
    "            norm: (str) - normalisation layer (layer/batch)\n",
    "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
    "            pool: (str) - global pooling function (sum/mean)\n",
    "            residual: (bool) - whether to use residual connections\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding lookup for initial node features\n",
    "        self.emb_in = torch.nn.LazyLinear(emb_dim)\n",
    "\n",
    "        # Stack of GNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.convs.append(EGNNLayer(emb_dim, activation, norm, aggr))\n",
    "\n",
    "        # Global pooling/readout function\n",
    "        self.pool = get_aggregation(pool)\n",
    "\n",
    "        self.residual = residual\n",
    "\n",
    "    @property\n",
    "    def required_batch_attributes(self) -> Set[str]:\n",
    "        return {\"x\", \"pos\", \"edge_index\", \"batch\"}\n",
    "\n",
    "    def forward(self, batch) -> EncoderOutput:\n",
    "        h = self.emb_in(batch.x)  # (n,) -> (n, d)\n",
    "        pos = batch.pos  # (n, 3)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            # Message passing layer\n",
    "            h_update, pos_update = conv(h, pos, batch.edge_index)\n",
    "\n",
    "            # Update node features (n, d) -> (n, d)\n",
    "            h = h + h_update if self.residual else h_update\n",
    "\n",
    "            # Update node coordinates (no residual) (n, 3) -> (n, 3)\n",
    "            pos = pos_update\n",
    "\n",
    "        return EncoderOutput({\n",
    "            \"node_embedding\": h,\n",
    "            \"graph_embedding\": self.pool(h, batch.batch),  # (n, d) -> (batch_size, d)\n",
    "            \"pos\": pos # Position\n",
    "        })\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a new model config file to accompany the custom `MyNewModel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference the `EGNN` config below (i.e., `proteinworkshop/config/encoder/egnn.yaml`) to fill out a custom `proteinworkshop/config/encoder/my_new_model.yaml`. This config file sets the actual values of the parameters of your model. The parameters present here will depend on the model you implemented; in the case of the `EGNN` model shown as demonstration in this tutorial, these parameters include the number of layers, the embedding dimension and the activation function used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "_target_: \"proteinworkshop.models.graph_encoders.egnn.EGNNModel\"\n",
    "num_layers: 6\n",
    "emb_dim: 512\n",
    "activation: relu\n",
    "norm: layer\n",
    "aggr: \"sum\"\n",
    "pool: \"sum\"\n",
    "residual: True\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compose and instantiate your config for pre-training or finetuning using your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to use the created config file in our code. To do this, we use `Hydra`, a library that helps with managing configuration options via `.yaml` files.\n",
    "\n",
    "In the following code block, we initialize Hydra and then compose the `cfg` object which we will later use to perform downstream or pre-training tasks. We can pass `hydra.compose` various overrides in order to customize our setup. We can specify for example:\n",
    "- the encoder to use (here our new custom model)\n",
    "- the task to perform later on\n",
    "- the dataset to use\n",
    "- the features that are used\n",
    "- which auxiliary test should be performed (if any)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:58:39.981335Z",
     "start_time": "2025-01-26T15:58:39.836397Z"
    }
   },
   "source": [
    "# Misc. tools\n",
    "import os\n",
    "\n",
    "# Hydra tools\n",
    "import hydra\n",
    "\n",
    "from hydra.compose import GlobalHydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "\n",
    "from proteinworkshop.constants import HYDRA_CONFIG_PATH\n",
    "from proteinworkshop.utils.notebook import init_hydra_singleton\n",
    "\n",
    "version_base = \"1.2\"  # Note: Need to update whenever Hydra is upgraded\n",
    "init_hydra_singleton(reload=True, version_base=version_base)\n",
    "\n",
    "path = HYDRA_CONFIG_PATH\n",
    "rel_path = os.path.relpath(path, start=\".\")\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "hydra.initialize(rel_path, version_base=version_base)\n",
    "\n",
    "cfg = hydra.compose(\n",
    "    config_name=\"train\",\n",
    "    overrides=[\n",
    "        \"encoder=gcpnet\",\n",
    "        \"task=inverse_folding\",\n",
    "        \"dataset=cath\",\n",
    "        \"features=ca_angles\",\n",
    "        \"+aux_task=none\",\n",
    "        \"dataset.datamodule.dataset_fraction=0.03\",\n",
    "    ],\n",
    "    return_hydra_config=True,\n",
    ")\n",
    "\n",
    "# Note: Customize as needed e.g., when running a sweep\n",
    "cfg.hydra.job.num = 0\n",
    "cfg.hydra.job.id = 0\n",
    "cfg.hydra.hydra_help.hydra_help = False\n",
    "cfg.hydra.runtime.output_dir = \"outputs\"\n",
    "\n",
    "HydraConfig.instance().set_config(cfg)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[01/26/25 15:58:39]\u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Hydra singleton cleared and ready to re-initialise.                     \u001B]8;id=214273;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py\u001B\\\u001B[2mnotebook.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=686681;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py#66\u001B\\\u001B[2m66\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/26/25 15:58:39] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Hydra singleton cleared and ready to re-initialise.                     <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">notebook.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py#66\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">66</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Hydra initialised at                                                    \u001B]8;id=140255;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py\u001B\\\u001B[2mnotebook.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=179886;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py#53\u001B\\\u001B[2m53\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[35m/Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop\u001B[0m \u001B[2m              \u001B[0m\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[35m/\u001B[0m\u001B[95mconfig.\u001B[0m                                                                \u001B[2m              \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Hydra initialised at                                                    <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">notebook.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/notebook.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">config.</span>                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use your custom model in a pre-training or finetuning task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the config object created, you can make use of the infrastructure that the Protein Workshop provides in order to directly use the config object for training or finetuning a model, depending on what your goal is."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:58:41.950599Z",
     "start_time": "2025-01-26T15:58:41.827071Z"
    }
   },
   "source": [
    "from proteinworkshop.configs import config\n",
    "from proteinworkshop.finetune import finetune\n",
    "from proteinworkshop.train import train_model\n",
    "\n",
    "cfg = config.validate_config(cfg)\n",
    "\n",
    "train_model(cfg)  # Pre-train a model using the selected data\n",
    "# finetune(cfg)  # Fine-tune a model using the selected data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m[01/26/25 15:58:41]\u001B[0m\u001B[2;36m \u001B[0m\u001B[33mWARNING \u001B[0m You are launching an inverse folding experiment with amino_acid_one_hot  \u001B]8;id=91412;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\u001B\\\u001B[2mconfig.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=134791;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#114\u001B\\\u001B[2m114\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         as a feature. This will be removed.                                      \u001B[2m             \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/26/25 15:58:41] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> You are launching an inverse folding experiment with amino_acid_one_hot  <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#114\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         as a feature. This will be removed.                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[32mDEBUG   \u001B[0m Requested CPUs: \u001B[1;36m16\u001B[0m. Avialable CPUs \u001B[1m(\u001B[0mphysical\u001B[1m)\u001B[0m: \u001B[1;36m12\u001B[0m. Requested CPU count   \u001B]8;id=209820;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\u001B\\\u001B[2mconfig.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=581803;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#312\u001B\\\u001B[2m312\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         will therefore be set to maximum number ofavailable physical cores.      \u001B[2m             \u001B[0m\n",
       "\u001B[2;36m                    \u001B[0m         NOTE: It is recommended to use N-1cores or less to avoid memory flush    \u001B[2m             \u001B[0m\n",
       "\u001B[2;36m                    \u001B[0m         overheads.                                                               \u001B[2m             \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Requested CPUs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>. Avialable CPUs <span style=\"font-weight: bold\">(</span>physical<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>. Requested CPU count   <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#312\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">312</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         will therefore be set to maximum number ofavailable physical cores.      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         NOTE: It is recommended to use N-1cores or less to avoid memory flush    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         overheads.                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[32mDEBUG   \u001B[0m CUDA available: \u001B[3;91mFalse\u001B[0m                                                    \u001B]8;id=177305;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\u001B\\\u001B[2mconfig.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=780478;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#247\u001B\\\u001B[2m247\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> CUDA available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>                                                    <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#247\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">247</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[32mDEBUG   \u001B[0m Requested GPUs: \u001B[1;36m1\u001B[0m.                                                       \u001B]8;id=527713;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\u001B\\\u001B[2mconfig.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=872434;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#248\u001B\\\u001B[2m248\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> Requested GPUs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.                                                       <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#248\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">248</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[32mDEBUG   \u001B[0m GPU count set to: \u001B[1;36m0\u001B[0m                                                      \u001B]8;id=475027;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\u001B\\\u001B[2mconfig.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=626430;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#253\u001B\\\u001B[2m253\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #008000; text-decoration-color: #008000\">DEBUG   </span> GPU count set to: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>                                                      <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#253\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">253</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[33mWARNING \u001B[0m You are not using early stopping.                                        \u001B]8;id=250620;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\u001B\\\u001B[2mconfig.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=552201;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#164\u001B\\\u001B[2m164\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> You are not using early stopping.                                        <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">config.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/configs/config.py#164\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating datamodule: <proteinworkshop.datasets.cath.CATHDataModule\u001B[33m...\u001B[0m \u001B]8;id=537486;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\u001B\\\u001B[2mtrain.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=507365;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#99\u001B\\\u001B[2m99\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating datamodule: &lt;proteinworkshop.datasets.cath.CATHDataModule<span style=\"color: #808000; text-decoration-color: #808000\">...</span> <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">train.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#99\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">99</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating callbacks\u001B[33m...\u001B[0m                                                \u001B]8;id=35708;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\u001B\\\u001B[2mtrain.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=963896;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#106\u001B\\\u001B[2m106\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating callbacks<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">train.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#106\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating callback \u001B[1m<\u001B[0m\u001B[1;95mlightning.pytorch.callbacks.ModelCheckpoint\u001B[0m\u001B[1m>\u001B[0m   \u001B]8;id=870905;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\u001B\\\u001B[2mcallbacks.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=192045;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\u001B\\\u001B[2m31\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.callbacks.ModelCheckpoint</span><span style=\"font-weight: bold\">&gt;</span>   <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating callback \u001B[1m<\u001B[0m\u001B[1;95mlightning.pytorch.callbacks.EarlyStopping\u001B[0m\u001B[1m>\u001B[0m     \u001B]8;id=35855;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\u001B\\\u001B[2mcallbacks.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=570567;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\u001B\\\u001B[2m31\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.callbacks.EarlyStopping</span><span style=\"font-weight: bold\">&gt;</span>     <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating callback \u001B[1m<\u001B[0m\u001B[1;95mlightning.pytorch.callbacks.RichModelSummary\u001B[0m\u001B[1m>\u001B[0m  \u001B]8;id=72738;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\u001B\\\u001B[2mcallbacks.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=166727;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\u001B\\\u001B[2m31\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.callbacks.RichModelSummary</span><span style=\"font-weight: bold\">&gt;</span>  <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating callback \u001B[1m<\u001B[0m\u001B[1;95mlightning.pytorch.callbacks.RichProgressBar\u001B[0m\u001B[1m>\u001B[0m   \u001B]8;id=287690;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\u001B\\\u001B[2mcallbacks.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=512292;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\u001B\\\u001B[2m31\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.callbacks.RichProgressBar</span><span style=\"font-weight: bold\">&gt;</span>   <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating callback                                                 \u001B]8;id=899088;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\u001B\\\u001B[2mcallbacks.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=35307;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\u001B\\\u001B[2m31\u001B[0m\u001B]8;;\u001B\\\n",
       "\u001B[2;36m                    \u001B[0m         \u001B[1m<\u001B[0m\u001B[1;95mlightning.pytorch.callbacks.LearningRateMonitor\u001B[0m\u001B[1m>\u001B[0m                      \u001B[2m               \u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating callback                                                 <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.callbacks.LearningRateMonitor</span><span style=\"font-weight: bold\">&gt;</span>                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating callback \u001B[1m<\u001B[0m\u001B[1;95mlightning.pytorch.callbacks.EarlyStopping\u001B[0m\u001B[1m>\u001B[0m     \u001B]8;id=993710;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\u001B\\\u001B[2mcallbacks.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=95492;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\u001B\\\u001B[2m31\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating callback <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.callbacks.EarlyStopping</span><span style=\"font-weight: bold\">&gt;</span>     <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/callbacks.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating loggers\u001B[33m...\u001B[0m                                                  \u001B]8;id=924324;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\u001B\\\u001B[2mtrain.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=383763;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#111\u001B\\\u001B[2m111\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating loggers<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                  <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">train.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#111\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating logger \u001B[1m<\u001B[0m\u001B[1;95mlightning.pytorch.loggers.csv_logs.CSVLogger\u001B[0m\u001B[1m>\u001B[0m      \u001B]8;id=545720;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/loggers.py\u001B\\\u001B[2mloggers.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=702368;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/loggers.py#31\u001B\\\u001B[2m31\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating logger <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">lightning.pytorch.loggers.csv_logs.CSVLogger</span><span style=\"font-weight: bold\">&gt;</span>      <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/loggers.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">loggers.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/utils/loggers.py#31\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2;36m                   \u001B[0m\u001B[2;36m \u001B[0m\u001B[34mINFO    \u001B[0m Instantiating trainer\u001B[33m...\u001B[0m                                                  \u001B]8;id=97214;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\u001B\\\u001B[2mtrain.py\u001B[0m\u001B]8;;\u001B\\\u001B[2m:\u001B[0m\u001B]8;id=337801;file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#114\u001B\\\u001B[2m114\u001B[0m\u001B]8;;\u001B\\\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Instantiating trainer<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                  <a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">train.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/dricpro/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py#114\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114</span></a>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':\nMisconfigurationException('`Trainer(devices=0)` value is not a valid input using mps accelerator.')\nfull_key: trainer",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMisconfigurationException\u001B[0m                 Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001B[0m, in \u001B[0;36m_call_target\u001B[0;34m(_target_, _partial_, args, kwargs, full_key)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_target_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/lightning/pytorch/utilities/argparse.py:70\u001B[0m, in \u001B[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;66;03m# all args were already moved to kwargs\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:396\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001B[0m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector \u001B[38;5;241m=\u001B[39m _DataConnector(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 396\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerator_connector \u001B[38;5;241m=\u001B[39m \u001B[43m_AcceleratorConnector\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_nodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43msync_batchnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msync_batchnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbenchmark\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbenchmark\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_distributed_sampler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_distributed_sampler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprecision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprecision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplugins\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplugins\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logger_connector \u001B[38;5;241m=\u001B[39m _LoggerConnector(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:146\u001B[0m, in \u001B[0;36m_AcceleratorConnector.__init__\u001B[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001B[0m\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerator_flag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_choose_gpu_accelerator_backend()\n\u001B[0;32m--> 146\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_device_config_and_set_final_flags\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_nodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_parallel_devices_and_init_accelerator()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:327\u001B[0m, in \u001B[0;36m_AcceleratorConnector._check_device_config_and_set_final_flags\u001B[0;34m(self, devices, num_nodes)\u001B[0m\n\u001B[1;32m    322\u001B[0m accelerator_name \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerator_flag\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerator_flag, Accelerator)\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerator_flag\n\u001B[1;32m    326\u001B[0m )\n\u001B[0;32m--> 327\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`Trainer(devices=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_devices_flag\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m)` value is not a valid input\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    329\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m using \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccelerator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m accelerator.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    330\u001B[0m )\n",
      "\u001B[0;31mMisconfigurationException\u001B[0m: `Trainer(devices=0)` value is not a valid input using mps accelerator.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mInstantiationException\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mproteinworkshop\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_model\n\u001B[1;32m      5\u001B[0m cfg \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mvalidate_config(cfg)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Topotein/ProteinWorkshop/proteinworkshop/train.py:115\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(cfg, encoder)\u001B[0m\n\u001B[1;32m    112\u001B[0m logger: List[Logger] \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mloggers\u001B[38;5;241m.\u001B[39minstantiate_loggers(cfg\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogger\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    114\u001B[0m log\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInstantiating trainer...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 115\u001B[0m trainer: L\u001B[38;5;241m.\u001B[39mTrainer \u001B[38;5;241m=\u001B[39m \u001B[43mhydra\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstantiate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogger\u001B[49m\n\u001B[1;32m    117\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cfg\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscheduler\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    121\u001B[0m         cfg\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39m_target_\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflash.core.optimizers.LinearWarmupCosineAnnealingLR\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    123\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m cfg\u001B[38;5;241m.\u001B[39mscheduler\u001B[38;5;241m.\u001B[39minterval \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    124\u001B[0m     ):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001B[0m, in \u001B[0;36minstantiate\u001B[0;34m(config, *args, **kwargs)\u001B[0m\n\u001B[1;32m    223\u001B[0m     _convert_ \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mpop(_Keys\u001B[38;5;241m.\u001B[39mCONVERT, ConvertMode\u001B[38;5;241m.\u001B[39mNONE)\n\u001B[1;32m    224\u001B[0m     _partial_ \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mpop(_Keys\u001B[38;5;241m.\u001B[39mPARTIAL, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m--> 226\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minstantiate_node\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_recursive_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_convert_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_partial_\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m OmegaConf\u001B[38;5;241m.\u001B[39mis_list(config):\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001B[39;00m\n\u001B[1;32m    231\u001B[0m     config_copy \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(config)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001B[0m, in \u001B[0;36minstantiate_node\u001B[0;34m(node, convert, recursive, partial, *args)\u001B[0m\n\u001B[1;32m    342\u001B[0m                 value \u001B[38;5;241m=\u001B[39m instantiate_node(\n\u001B[1;32m    343\u001B[0m                     value, convert\u001B[38;5;241m=\u001B[39mconvert, recursive\u001B[38;5;241m=\u001B[39mrecursive\n\u001B[1;32m    344\u001B[0m                 )\n\u001B[1;32m    345\u001B[0m             kwargs[key] \u001B[38;5;241m=\u001B[39m _convert_node(value, convert)\n\u001B[0;32m--> 347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_target\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_target_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    349\u001B[0m     \u001B[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001B[39;00m\n\u001B[1;32m    350\u001B[0m     \u001B[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001B[39;00m\n\u001B[1;32m    351\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert \u001B[38;5;241m==\u001B[39m ConvertMode\u001B[38;5;241m.\u001B[39mALL \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m    352\u001B[0m         convert \u001B[38;5;129;01min\u001B[39;00m (ConvertMode\u001B[38;5;241m.\u001B[39mPARTIAL, ConvertMode\u001B[38;5;241m.\u001B[39mOBJECT)\n\u001B[1;32m    353\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m node\u001B[38;5;241m.\u001B[39m_metadata\u001B[38;5;241m.\u001B[39mobject_type \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28mdict\u001B[39m)\n\u001B[1;32m    354\u001B[0m     ):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Topotein/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001B[0m, in \u001B[0;36m_call_target\u001B[0;34m(_target_, _partial_, args, kwargs, full_key)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m full_key:\n\u001B[1;32m     96\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mfull_key: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 97\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m InstantiationException(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mInstantiationException\u001B[0m: Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':\nMisconfigurationException('`Trainer(devices=0)` value is not a valid input using mps accelerator.')\nfull_key: trainer"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we instantiated the config, we specified `ca_angles` as feature context. However, we can easily reconfigure the custom model to use side-chain atom context as you can see in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_base = \"1.2\"  # Note: Need to update whenever Hydra is upgraded\n",
    "init_hydra_singleton(reload=True, version_base=version_base)\n",
    "\n",
    "path = HYDRA_CONFIG_PATH\n",
    "rel_path = os.path.relpath(path, start=\".\")\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "hydra.initialize(rel_path, version_base=version_base)\n",
    "\n",
    "cfg = hydra.compose(\n",
    "    config_name=\"train\",\n",
    "    overrides=[\n",
    "        \"encoder=my_new_model\",\n",
    "        \"task=inverse_folding\",\n",
    "        \"dataset=afdb_swissprot_v4\",\n",
    "        \"features=ca_sc\",\n",
    "        \"+aux_task=none\",\n",
    "    ],\n",
    "    return_hydra_config=True,\n",
    ")\n",
    "\n",
    "# Note: Customize as needed e.g., when running a sweep\n",
    "cfg.hydra.job.num = 0\n",
    "cfg.hydra.job.id = 0\n",
    "cfg.hydra.hydra_help.hydra_help = False\n",
    "cfg.hydra.runtime.output_dir = \"outputs\"\n",
    "\n",
    "HydraConfig.instance().set_config(cfg)\n",
    "\n",
    "cfg = config.validate_config(cfg)\n",
    "\n",
    "# train_model(cfg)  # Pre-train a model using the selected data\n",
    "# finetune(cfg)  # Fine-tune a model using the selected data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Wrapping up\n",
    "\n",
    "Have any additional questions about adding your custom model to the `ProteinWorkshop`? [Create a new issue](https://github.com/a-r-j/ProteinWorkshop/issues/new/choose) on our [GitHub repository](https://github.com/a-r-j/ProteinWorkshop). We would be happy to work with you to add your new model to the repository!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
